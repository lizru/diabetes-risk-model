{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5d2061",
   "metadata": {},
   "source": [
    "# Diabetes Prediction Modeling\n",
    "This notebook trains a machine learning model that aims to predict whether a person has prediabetes or diabetes through a variety of health indicators. The data is sourced from Kaggle, found here: https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/data?select=diabetes_012_health_indicators_BRFSS2015.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1a029f",
   "metadata": {},
   "source": [
    "## Dependencies & Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96161072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import shap\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, accuracy_score, f1_score\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer, fbeta_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message=\"X does not have valid feature names\")\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab91e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes_012_health_indicators_BRFSS2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83586a3",
   "metadata": {},
   "source": [
    "## Inspecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717dfcd",
   "metadata": {},
   "source": [
    "The data source includes cleaned 253,680 self-reported telephone survery responses from the CDC's Behavioral Risk Factor Surveillance System (BRFSS), which collects health information across adults in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3543e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Shape: \", df.shape)\n",
    "df.head()\n",
    "df.info()\n",
    "print(\"Missing values: \", df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9ebd21",
   "metadata": {},
   "source": [
    "We can see that the data has 22 columns spanning various health features. It includes the following columns:\n",
    "- **Diabetes status**: 3 classes — no diabetes (0), prediabetes (1), or diabetes (2)\n",
    "- **High blood pressure**: 0 = No, 1 = Yes\n",
    "- **High cholesterol**: 0 = No, 1 = Yes\n",
    "- **Cholesterol check**: 0 = No cholesterol check in 5 years, 1 = Yes\n",
    "- **BMI**: Body Mass Index (numerical)\n",
    "- **Smoking history**: 0 = Never smoked 100+ cigarettes, 1 = Has smoked\n",
    "- **Stroke history**: 0 = No, 1 = Yes\n",
    "- **Heart disease or attack**: 0 = No CHD or MI, 1 = Yes\n",
    "- **Physical activity**: 0 = No activity in past 30 days, 1 = Yes\n",
    "- **Fruit consumption**: 0 = Eats fruit <1 time/day, 1 = Eats ≥1 time/day\n",
    "- **Vegetable consumption**: 0 = Eats veggies <1 time/day, 1 = Eats ≥1 time/day\n",
    "- **Heavy alcohol consumption**: 0 = No, 1 = Yes (men >14/week, women >7/week)\n",
    "- **Healthcare access**: 0 = No coverage, 1 = Has coverage\n",
    "- **Doctor cost barrier**: 0 = Could afford, 1 = Could not see doctor due to cost\n",
    "- **General health**: Self-reported: 1 = Excellent, 5 = Poor\n",
    "- **Mental health days**: Days (0–30) mental health was not good (past 30 days)\n",
    "- **Physical health days**: Days (0–30) physical health was not good (past 30 days)\n",
    "- **Walking difficulty**: 0 = No, 1 = Serious difficulty walking/climbing stairs\n",
    "- **Sex**: 0 = Female, 1 = Male\n",
    "- **Age group**: 1 = 18–24, ..., 13 = 80+\n",
    "- **Education level**: 1 = No schooling, ..., 6 = College graduate\n",
    "- **Income level**: 1 = <$10k, ..., 8 = $75k+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0feee",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff156984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions used in EDA\n",
    "\n",
    "def get_categorical_features(df, target=\"Diabetes_012\"):\n",
    "    \"\"\"Returns a list of categorical feature column names, excluding the target.\"\"\"\n",
    "    cat_cols = [\n",
    "        'HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke',\n",
    "        'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
    "        'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
    "        'DiffWalk', 'Sex', 'Education', 'Income', 'Age'\n",
    "    ]\n",
    "    \n",
    "    cat_cols = [col for col in cat_cols if col != target]\n",
    "    return cat_cols\n",
    "\n",
    "def get_numerical_features(df, target=\"Diabetes_012\"):\n",
    "    \"\"\"Returns a list of numerical feature column names.\"\"\"\n",
    "    num_cols = ['BMI', 'MentHlth', 'PhysHlth']\n",
    "    num_cols = [col for col in num_cols if col != target]\n",
    "    return num_cols\n",
    "\n",
    "\n",
    "def get_features(df, target='Diabetes_012'):\n",
    "    \"\"\"Returns a list of df columns excluding the target.\"\"\"\n",
    "    return [col for col in df.columns if col!= target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d314f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions\n",
    "\n",
    "\n",
    "def plot_target_distributions(df, target_feature):\n",
    "    \"\"\"Prints & plots the distribution of the target variable.\"\"\"\n",
    "\n",
    "    # Finds counts & percentages\n",
    "    counts = df[target_feature].value_counts()\n",
    "    percentages = df[target_feature].value_counts(normalize=True) * 100  \n",
    "    summary = pd.DataFrame({'Count': counts, 'Percentage (%)': percentages})\n",
    "    print(summary)\n",
    "\n",
    "    # Countplot\n",
    "    sns.countplot(x = target_feature, data=df)\n",
    "    plt.title(f\"Distribution of Target: {target_feature}\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_histograms(df, features):\n",
    "    \"\"\"Plot histograms for specified numerical features with a grid layout.\"\"\"\n",
    "    for feature in features:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "        sns.histplot(df[feature], bins=30, ax=axes[0])\n",
    "        axes[0].set_title(f\"Histogram of {feature}\")\n",
    "        axes[0].set_xlabel(feature)\n",
    "        axes[0].set_ylabel(\"Count\")\n",
    "\n",
    "        sns.boxplot(x=df[feature], ax=axes[1])\n",
    "        axes[1].set_title(f\"Boxplot of {feature}\")\n",
    "        axes[1].set_xlabel(feature)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_feature_countplots(df, features):\n",
    "    \"\"\"Plot countplots for categorical features.\"\"\"\n",
    "    for feature in features:\n",
    "        sns.countplot(x=feature, data=df)\n",
    "        plt.title(f\"Distribution of {feature}\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_target_distributions(df, \"Diabetes_012\")\n",
    "plot_feature_histograms(df, get_numerical_features(df))\n",
    "plot_feature_countplots(df, get_categorical_features(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34577512",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Numerical Features\n",
    "- BMI: Approximately normal distribution when excluding outliers; strong right skew due to high outliers (BMI up to ~100, which is plausible in clinical data).\n",
    "- Poor Mental Health Days: Right-skewed. Majority report 0 days; upper quartile around 5 days; some individuals report up to 30 days.\n",
    "- Poor Physical Health Days: Similar to mental health days. Majority report 0 days; upper quartile up to about a week; outliers up to 30 days.\n",
    "\n",
    "\n",
    "Categorical Features\n",
    "- Age Group (binned): Dataset represents adults, with a higher proportion of middle-aged and older individuals. Younger adults are underrepresented.\n",
    "- Income Group (binned): Left-skewed, with high representation of individuals earning $75k or more.\n",
    "- High Blood Pressure / High Cholesterol / Smoking: Most records report \"No,\" but a substantial minority report \"Yes.\"\n",
    "- Cholesterol Check: A small number of individuals have not had a cholesterol check in the past 5 years. \"High cholesterol\" values for these records should be flagged or excluded to avoid misleading results.\n",
    "- History of Stroke / Heart Disease or Attack: Rare but present in a small percentage of patients.\n",
    "- Physical Activity: Most individuals report physical activity in the past 30 days.\n",
    "- Fruit and Vegetable Consumption: Most consume vegetables daily; fewer eat at least one fruit daily. A notable portion report not consuming either daily.\n",
    "- Alcohol Consumption: The vast majority of individuals do not report heavy alcohol consumption.\n",
    "- Healthcare Coverage / Doctor Affordability: The vast majority of individuals report having healthcare coverage and being able to afford medical care.\n",
    "- General Health: Most commonly reported as 2 (on a 1–5 scale, with 1 being best), with a slight right skew toward poorer health.\n",
    "- Serious Difficulty Walking: Small but notable minority report serious difficulty walking.\n",
    "- Sex: Slight overrepresentation of females.\n",
    "- Education Level: High proportion of college graduates.\n",
    "\n",
    "The dataset represents adults, with a higher proportion of middle-aged and older individuals.\n",
    "\n",
    "Income and education levels are skewed toward higher socioeconomic status, possibly reflecting sampling bias. The prediction model may not generalize as well to young adults or those with lower socioeconomic status due to their lower representation in the dataset.\n",
    "\n",
    "\n",
    "\n",
    "### Outliers\n",
    "There are many outliers in the distributions of BMI, poor mental health days in the past month, and poor physical health days in the past month. While uncommon, these values are likely valid- BMIs close to 100 are rare but possible, and some chronic conditions or episodes may lead to poor mental or physical health for all days in a month. Because of their clinical plausibility, we will keep these outliers rather thann remove or cap them to preserve the integrity of the dataset. However, it is important to remember that extreme values can influence certain modeling technqiues and summary statistics.\n",
    "\n",
    "### Class Imbalance\n",
    "Our dataset is highly imbalanced in the target variable, diabetes status. Approximately 84% of individuals do not have diabetes, about 14% have diabetes, and just under 2% are classified as having prediabetes. this imbalance means that the prediabetes group is very small and can easily be overlooked by predictive models if it is not handled correctly. Models trained on imbalanced data can become biased to the majority class of no diabetes, which results in poor sensitivity in detecting minority classes. Techniques like resampling and class weighting can be used during model training to mitiage the effect of the imbalance and improve detection of rare cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d499257",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Feature engineering to transform skewed numeric features and create interaction features.\n",
    "\n",
    "BMI and mental/physical health days are binned to get organized categories for analysis.\n",
    "\n",
    "Fruits and Veggies columns are combined for simplicity.\n",
    "\n",
    "Interactoin terms are created between features that are likely to to be correlated to provide further insight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9fb9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def total_poor_health_days(df, mental_health='MentHlth', phys_health='PhysHlth'):\n",
    "    \"\"\" Creates a new total health day column by adding mental and physical days.\"\"\"\n",
    "    df['TotalHealthDays'] = df[mental_health] + df[phys_health]\n",
    "    return df\n",
    "\n",
    "\n",
    "def bin_bmi(df, bmi_col='BMI'):\n",
    "    \"\"\"\n",
    "    Bins BMI into its labeled categories:\n",
    "    - Underweight BMI < 18.5,\n",
    "    - Normal: 18.5 <= BMI < 25\n",
    "    - Overweight: 25 <= BMI < 30\n",
    "    - Obese: 30 <= BMI < 40\n",
    "    - Extreme Obese: BMI >= 40\n",
    "    \"\"\"\n",
    "\n",
    "    bmi_bins = [0, 18.5, 25, 30, 40, 200]\n",
    "    bmi_labels = ['underweight', 'normal', 'overweight', 'obese', 'extreme_obese']\n",
    "\n",
    "    # returns a series of bmi bins to apply to df\n",
    "    return pd.cut(df[bmi_col], bins=bmi_bins, labels=bmi_labels, right=False)\n",
    "\n",
    "def bin_health_days(df, health_col):\n",
    "    \"\"\"Bins physical and mental health days according to severity.\"\"\"\n",
    "    \n",
    "    # Include -1 to create the bin of 0 days reported\n",
    "    health_bins = [-1, 0, 5, 15, 30]\n",
    "    health_labels = ['none', 'mild', 'moderate', 'severe']\n",
    "    return pd.cut(df[health_col], bins=health_bins, labels=health_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_interaction_term(df, col1, col2, new_col_name, mapping=None, drop_original=False):\n",
    "    \"\"\"\n",
    "    Creates interaction terms between columns. \n",
    "\n",
    "    Parameters:\n",
    "    df: the DataFrame being modified\n",
    "    col1: the first original column name\n",
    "    col2: the second original column name\n",
    "    new_col_name: the name of the created interaction column\n",
    "    mapping: a dictionary that maps values (11 -> both true)\n",
    "    drop_original: boolean indicating if original column will be dropped.\n",
    "\n",
    "    Returns the modified DataFrame.\n",
    "    \"\"\"\n",
    "    # convert the two cols to ints rather than floating point binary\n",
    "    col1_vals = pd.to_numeric(df[col1], errors='coerce').dropna().astype(int)\n",
    "    col2_vals = pd.to_numeric(df[col2], errors='coerce').dropna().astype(int)\n",
    "\n",
    "    # add the two values as a str together\n",
    "    combined_vals = col1_vals.astype(str) + col2_vals.astype(str)\n",
    "\n",
    "    # if a map is given, map the string to the output\n",
    "    if mapping:\n",
    "        df[new_col_name] = combined_vals.map(mapping).astype('category')\n",
    "    else:\n",
    "        df[new_col_name] = combined_vals.astype('category')\n",
    "\n",
    "    if drop_original:\n",
    "            df.drop([col1,col2], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# mapping\n",
    "fruit_veg_mapping = {\n",
    "    '11': 'both',\n",
    "    '10': 'fruit_only',\n",
    "    '01': 'veg_only',\n",
    "    '00': 'none'\n",
    "}\n",
    "\n",
    "smoke_activity_mapping = {\n",
    "    '11': 'smoker_active',\n",
    "    '10': 'smoker_inactive',\n",
    "    '01': 'non_smoker_active',\n",
    "    '00': 'non_smoker_inactive'\n",
    "}\n",
    "\n",
    "coverage_afford_mapping = {\n",
    "    '11': 'covered_cannot_afford',\n",
    "    '10': 'covered_afford',\n",
    "    '01': 'uncovered_cannot_afford',\n",
    "    '00': 'uncovered_afford'\n",
    "}\n",
    "\n",
    "def collapse_risk(df):\n",
    "    ''' Collapse the 1 & 2 signifying diabetes into risk of diabetes. '''\n",
    "    df['DiabetesBinary'] = df['Diabetes_012'].replace({1: 1, 2: 1, 0: 0})\n",
    "    return df\n",
    "\n",
    "# apply functions\n",
    "df = total_poor_health_days(df)\n",
    "df['bmi_bin'] = bin_bmi(df)\n",
    "df['poor_mental_health'] = bin_health_days(df,'MentHlth')\n",
    "df['poor_physical_health'] = bin_health_days(df,'PhysHlth')\n",
    "df = create_interaction_term(df, 'Fruits', 'Veggies', new_col_name='FruitVeg', mapping=fruit_veg_mapping, drop_original=True)\n",
    "df = create_interaction_term(df, 'Smoker', 'PhysActivity', new_col_name='SmokeActivity', mapping=smoke_activity_mapping)\n",
    "df = create_interaction_term(df, 'AnyHealthcare', 'NoDocbcCost', new_col_name='HealthAccess', mapping=coverage_afford_mapping, drop_original=True)\n",
    "df = collapse_risk(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a0a9e",
   "metadata": {},
   "source": [
    "Since this project involves healthcare data, model interpretability is an important consideration. Using an interpretable model helps both patients and healthcare providers understand the main factors driving diabetes risk, which can guide more informed decisions about lifestyle changes and treatment options. For instance, identifying that high BMI or low physical activity are strong risk factors can support targeted interventions. Furthermore, it is important to be able to trust any health decisions generated by a model, and black box models can create obstacles in this due to lack of transperency. However, if the goal is simply to accurately identify individuals at risk for further screening, then interpretability may be less of a priority. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87591537",
   "metadata": {},
   "source": [
    "The dataset is very imbalanced, specifically for prediabetes. There are many methods to address this, including undersampling the dominant classes, oversampling the smaller classes through techniques like SMOTE, or using class weights. Over/undersampling adds an exra step in the preprocessing stage, and comes with either losing data or relying on syntehtic data, which can add noise or overfit to training sets. Additionally, modern models such as LightGBM or XGBoost that are able to handle class imbalances better. When evaluating models, its also more important to look at f1, precision, and recall, as accuracy alone could be misleading if it is completely missing the minority class. Choosing a LightGBM or XGBoost model could help with the class imbalance without the risks of losing data or using synthetic data points. However, it comes with less interprebility than simpler models. Using SHAP values can help us evaluate feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae5bc7",
   "metadata": {},
   "source": [
    "For simplicity in this project, we will collapse prediabtetes and diabetes into one category in order to provide an idea of risk levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b34933",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "We begin with a baseline model to set a minimum expectation for a more complex model's performance and for interprebility. We choose to use a logistic regression model for its simplicity and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c47fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cols(df, ignore_chol=False):\n",
    "    '''\n",
    "    Returns the columns of the df as three lists for preprocessing: numerical, binary, and categorical.\n",
    "    ignore_chol is added to evaluate effects of potential data leakage later in the notebook.\n",
    "    '''\n",
    "\n",
    "    num_cols = [c for c in ['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income', 'TotalHealthDays'] if c in df.columns]\n",
    "    if not ignore_chol:\n",
    "        binary_cols = [c for c in ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', \n",
    "                   'PhysActivity', 'HvyAlcoholConsump', 'DiffWalk', 'Sex'] if c in df.columns]\n",
    "    else:\n",
    "        binary_cols = [c for c in ['HighBP', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', \n",
    "                   'PhysActivity', 'HvyAlcoholConsump', 'DiffWalk', 'Sex'] if c in df.columns]\n",
    "    \n",
    "    cat_cols = [c for c in ['bmi_bin', 'FruitVeg', 'SmokeActivity', 'HealthAccess', 'poor_mental_health', 'poor_physical_health'] if c in df.columns]\n",
    "    return num_cols, binary_cols, cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e877b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def baseline_model_pipeline(df):\n",
    "    '''\n",
    "     Prepares a logistic regression pipeline and returns features and target for diabetes risk prediction.\n",
    "\n",
    "    - Collapses the multi-class diabetes indicator into a binary target (diabetes risk).\n",
    "    - Identifies numerical, binary, and categorical feature columns.\n",
    "    - Builds a pipeline that preprocesses features appropriately (scaling, one-hot encoding, passthrough).\n",
    "    - Sets up a logistic regression classifier with class balancing.\n",
    "\n",
    "    Returns:\n",
    "    clf: The model pipeline with preprocessing and logistic regression classifier.\n",
    "    X:  The feature dataframe after dropping target columns.\n",
    "    y:  The binary target variable indicating diabetes risk.\n",
    "\n",
    "    '''\n",
    "\n",
    "    \n",
    "\n",
    "    # collapsing the risk for the model, \n",
    "    df = collapse_risk(df)\n",
    "    print(df['DiabetesBinary'].value_counts(normalize=True))\n",
    "\n",
    "    # splitting columns\n",
    "    num_cols, binary_cols, cat_cols = split_cols(df)\n",
    "\n",
    "\n",
    "    # defining train and test\n",
    "    X = df.drop(columns=['Diabetes_012', 'DiabetesBinary'])\n",
    "    y = df['DiabetesBinary']\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        # standardize numerics, leave binaries as is, onehot encode categorical\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('bin', 'passthrough', binary_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ], remainder='drop')\n",
    "\n",
    "    clf = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))\n",
    "    ])\n",
    "\n",
    "    return clf, X, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(clf, X, y, cv=5, threshold=.5):\n",
    "    '''\n",
    "    Evaluates model accuracy through metrics and confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - clf: The classifier model pipeline\n",
    "    - X: The feature dataframe after dropping target columns.\n",
    "    - y: The binary target variable indicating diabetes risk.\n",
    "    - cv: num cv folds\n",
    "    - threshold: threshold for converting prebabilities to predictions.\n",
    "\n",
    "    Prints metrics, no returns.\n",
    "    '''\n",
    "\n",
    "    # Using stratified K-folds for even cross validation\n",
    "    stratified_cv = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "    # finding cv probabilities, then converting to binary predict w/ given threshold\n",
    "    y_probs = cross_val_predict(clf, X, y, cv=stratified_cv, method='predict_proba')\n",
    "    y_pred = (y_probs[:,1] >= threshold).astype(int)\n",
    "\n",
    "    # calculate scoring metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    \n",
    "    # Get cross-validated predictions for confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['No Diabetes', 'Diabetes'],\n",
    "                yticklabels=['No Diabetes', 'Diabetes'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # print classification report\n",
    "    print(classification_report(y, y_pred, target_names=['No Diabetes', 'Diabetes']))\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y, y_probs[:, 1])\n",
    "    avg_prec = average_precision_score(y, y_probs[:, 1])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, label=f'PR Curve (AP = {avg_prec:.2f})', color='purple')\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "base_clf, base_X, base_y = baseline_model_pipeline(df)\n",
    "evaluate_model(base_clf, base_X, base_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c214abc",
   "metadata": {},
   "source": [
    "The baseline regression model has an accuracy of .73, but the F1 is only .47. This is because the recall is .77, meaning that the model caches about 77% of actual diabetes cases, but has a precision of .34, meaning that it when it predicts diabetes, it is only correct about 34% of the time, meaning that there are many false positives. The accuracy is heavily influenced by the majority class size. While the accuracy might look like a decent baseline, the F1 score shows how the imbalance in data can make that metric misleading; it is essential to look at other scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8c117",
   "metadata": {},
   "source": [
    "## Second Model\n",
    "The logistic regression model can be improved with hyperparamter tuning or different feature engineering, but it is not ideal for handling imbalanced data. Tree-based models like LIghtGBM and XGBoost can handle imbalanced data better and capture nonlinear relationships that logistic regression often misses. Using these models can provide a boost in performance with less manual tuning or changes in feature engineering.\n",
    "\n",
    "LightGBM will be used as it is fast and efficient on larger datasets like this one. While interpretability matters here, LightGBM lets us use tools like SHAP values to understand whcih features drive the model's predictions, making results more transparent and trustworthy in a medical context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_model_pipeline(df, ignore_chol=False):\n",
    "    '''\n",
    "    Prepares a LightGBM pipeline and returns features and target.\n",
    "    - Collapses multi-class indicator into binary diabetes risk target\n",
    "    - Builds a pipeline that scales and encodes features \n",
    "    - Sets up the LightGBM classifier\n",
    "\n",
    "    Returns:\n",
    "    clf: the model pieline with preprocessing and LightGBM classifier\n",
    "    X: the feature dataframe after dropping target\n",
    "    y: the binary target of diabetes risk\n",
    "    \n",
    "    '''\n",
    "\n",
    "    df = collapse_risk(df)\n",
    "    num_cols, binary_cols, cat_cols = split_cols(df, ignore_chol)\n",
    "\n",
    "    X = df.drop(columns=['Diabetes_012', 'DiabetesBinary'])\n",
    "    y = df['DiabetesBinary']\n",
    "\n",
    "    # ignore cholestorel from training if true & if they exist in df\n",
    "    if ignore_chol:\n",
    "        chol_cols = ['HighChol', 'CholCheck']\n",
    "        cols_to_drop = [col for col in chol_cols if col in X.columns]\n",
    "        if cols_to_drop:\n",
    "            X = X.drop(columns=cols_to_drop)\n",
    "\n",
    "        \n",
    "    # handling imbalance by creating a weight\n",
    "    neg_count = sum(y == 0)\n",
    "    pos_count = sum(y == 1)\n",
    "    scale_pos_weight = neg_count / pos_count\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('bin', 'passthrough', binary_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ], remainder = 'drop')\n",
    "\n",
    "    clf = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LGBMClassifier(random_state=42, verbose = -1, scale_pos_weight=scale_pos_weight))\n",
    "    ])\n",
    "\n",
    "    return clf, X, y\n",
    "\n",
    "\n",
    "def run_base_lgbm(df):\n",
    "    lgbm_clf, lgbm_X, lgbm_y = lgbm_model_pipeline(df)\n",
    "    evaluate_model(lgbm_clf, lgbm_X, lgbm_y)\n",
    "    return lgbm_clf, lgbm_X, lgbm_y\n",
    "\n",
    "lgbm_clf, lgbm_X, lgbm_y = run_base_lgbm(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b308f7",
   "metadata": {},
   "source": [
    "This model has improved recall, but still struggles with precision. In order to achieve a better F1, we will tune the hyperparameters. We use a randomized search to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e10730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SHAP for model analysis\n",
    "def get_shap_explainer(clf_pipeline, X, sample_size=15000):\n",
    "    ''''\n",
    "    Generates SHAP values for the given pipelne and input features.\n",
    "\n",
    "    Parameters:\n",
    "    clf_pipeline: fitted pipeline (preprocessing & LightGBM classifier)\n",
    "    X: feature input\n",
    "    sample_size: n samples to use for SHAP set to 1k for speed\n",
    "\n",
    "    '''\n",
    "    # sample feature data for speed\n",
    "    X_sample = X.sample(n=min(sample_size,len(X)), random_state=42)\n",
    "\n",
    "    # extract steps of lgbm pipeline\n",
    "    model = clf_pipeline.named_steps['classifier']\n",
    "    preprocessor = clf_pipeline.named_steps['preprocessor']\n",
    "\n",
    "    # process feature input and collect names\n",
    "    X_processed = preprocessor.transform(X_sample)\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "    # compute SHAP\n",
    "    explainer = shap.Explainer(model, X_processed, feature_names=feature_names)\n",
    "    shap_vals = explainer(X_processed)\n",
    "    shap.summary_plot(shap_vals, X_processed, feature_names=feature_names)\n",
    "\n",
    "\n",
    "def randomized_search_lgbm_pipeline(clf, X, y, param_dis, n_iter=50, cv=5, scoring='f1'):\n",
    "    '''\n",
    "    Performs Randomized Search CV on the LightGBM pipeline.\n",
    "\n",
    "    Parameters:\n",
    "    clf: the LightGBM pipeline\n",
    "    X: features\n",
    "    y: target \n",
    "    param_dis: paramtetres to search over\n",
    "    n_iter: num parameter settings sampled\n",
    "    cv: number of cv folds\n",
    "    scoring: metric to optimize by\n",
    "\n",
    "    Returns: \n",
    "    best_model: model with best found parameters\n",
    "    cv_results: results of the grid search\n",
    "    '''\n",
    "\n",
    "\n",
    "    stratified_cv = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    random_search = RandomizedSearchCV(estimator=clf, param_distributions=param_dis, n_iter=n_iter, scoring=scoring, cv=stratified_cv, n_jobs=-1, refit=True, random_state=42)\n",
    "\n",
    "    random_search.fit(X, y)\n",
    "\n",
    "    print(f\"Best {scoring} score: {random_search.best_score_:.4f}\")\n",
    "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "\n",
    "    best_model = random_search.best_estimator_\n",
    "    cv_results = random_search.cv_results_\n",
    "\n",
    "    return best_model, cv_results\n",
    "\n",
    "\n",
    "# setting a paramter grid based on commonly tested values for LightGBM tuning & imbalance ration\n",
    "param_grid = {\n",
    "    'classifier__num_leaves': [31, 50, 100],\n",
    "    'classifier__learning_rate': [0.005, 0.01, 0.05],\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [-1, 10, 20],\n",
    "    'classifier__scale_pos_weight': [1, 5, 5.7, 6] \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a f2 score to prioritize recall\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "# line below finds hyperparams. commented out to avoid accidental repeat evaluation\n",
    "# best_model, cv_results = randomized_search_lgbm_pipeline(lgbm_clf, lgbm_X, lgbm_y, param_grid, n_iter=50, cv=5, scoring=f2_scorer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa25028",
   "metadata": {},
   "source": [
    "The output from randomized search gives us the best parameters for F2 in this model, which addresses precision and recall with emphasis on recall. We assign  the updated parameters to the LightGBM classifier for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dfdc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set tuned hyperparamters\n",
    "def set_best_params(lgbm_clf):\n",
    "    '''Sets the params to the classifier part of the pipeline. Values hardcoded from RandomizedSearchCV.'''\n",
    "    best_params = {'scale_pos_weight': 6, 'num_leaves': 31, 'n_estimators': 200, 'max_depth': -1, 'learning_rate': 0.05}\n",
    "    lgbm_clf.named_steps['classifier'].set_params(**best_params)\n",
    "    return lgbm_clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd47e681",
   "metadata": {},
   "source": [
    "We can also find the best threshold for the calculated probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0f3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_best_threshold(model, X_val, y_val,beta=2):\n",
    "    '''\n",
    "    Finds the best classification threshold to maximize the default F2 score.\n",
    "\n",
    "    model: the fitted pipeline \n",
    "    X_val: validation features\n",
    "    y_val: validation labels\n",
    "    beta: F-beta score, default of 2\n",
    "    '''\n",
    "    y_probs = model.predict_proba(X_val)[:,1]\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_val, y_probs)\n",
    "\n",
    "    beta_sq = beta ** 2\n",
    "\n",
    "    # F2 is calculated w/ avoiding dividing by 0\n",
    "    fbeta_scores = np.divide(\n",
    "        (1 + beta_sq) * precisions * recalls,\n",
    "        (beta_sq * precisions) + recalls,\n",
    "        out=np.zeros_like(precisions),\n",
    "        where=((beta_sq * precisions) + recalls) != 0\n",
    "    )\n",
    "\n",
    "    fbeta_scores = fbeta_scores[:-1]\n",
    "    thresholds = thresholds\n",
    "\n",
    "    best_i = fbeta_scores.argmax()\n",
    "    best_threshold = thresholds[best_i]\n",
    "    print(f\"Best threshold: {best_threshold:.2f} with F2 of {fbeta_scores[best_i]:.2f}\")\n",
    "    return best_threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a11fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find the best threshold\n",
    "def tuned_model(lgbm_clf, lgbm_X, lgbm_y, run_shap=True):\n",
    "    '''Sets best parameters, fits the model to data, finds best threshold, & evaluates the model. '''\n",
    "    X_train, X_val, y_train, y_val = train_test_split(lgbm_X, lgbm_y, test_size=0.2, stratify=lgbm_y, random_state=42)\n",
    "    lgbm_clf = set_best_params(lgbm_clf)\n",
    "    lgbm_clf.fit(X_train, y_train)\n",
    "    best_thresh = find_best_threshold(lgbm_clf, X_val, y_val)\n",
    "    evaluate_model(lgbm_clf, X_val, y_val, threshold=best_thresh)\n",
    "    if run_shap:\n",
    "        get_shap_explainer(lgbm_clf, X_train)\n",
    "\n",
    "\n",
    "\n",
    "tuned_model(lgbm_clf, lgbm_X, lgbm_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22382b04",
   "metadata": {},
   "source": [
    "From this, we can see that the ideal threshold will be .42 instead of the default .5, which provides a small boost in F2 score. The model can now be evaluated again with the new parameters and threshold. We observe a noticeable improvement in recall for diabetes, which has increased to .85 from the previous score of .79. However, precision has lowered from .33 to .30.  While the model catches more of the true diabetes cases, overall accuracy has decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5403a44b",
   "metadata": {},
   "source": [
    "### SHAP Interpretation\n",
    "The features with largest impact on the model's diabetes risk prediction were self reported general health, age, presence of high blood pressure, BMI, and presence of high cholestorol. Income has a substansial effect, which could point towards healthcare accessibility. Heavy alcohol consumption is likely a confounding variable, as it is associated with lower risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86de41e5",
   "metadata": {},
   "source": [
    "## Further LightGBM adjustments\n",
    "An ensemble stacking the LightGBM and logistic regression model is used to check for any boost in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f5292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying ensemble to see if it provides a boost\n",
    "\n",
    "def stack_pipeline(df):\n",
    "    logreg_clf, X, y = baseline_model_pipeline(df)\n",
    "    lgbm_clf, _, _ = lgbm_model_pipeline(df)\n",
    "    lgbm_clf = set_best_params(lgbm_clf)\n",
    "\n",
    "\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('logreg', logreg_clf),\n",
    "            ('lgbm', lgbm_clf)\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(max_iter=1000, class_weight={0:1, 1:4}),\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "    best_thresh = find_best_threshold(stacking_clf, X_val, y_val) +.03\n",
    "    evaluate_model(stacking_clf, X_val, y_val, threshold=best_thresh)\n",
    "\n",
    "stack_pipeline(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14be78d3",
   "metadata": {},
   "source": [
    "Stacking the two models were already built did not provide a signficant increase in F1, and is likely not worth the added complexity. While the metrics for logistic regression and LightGBM were not all the same, there is not a dramatic enough difference in the two for stacking to provide further insight.\n",
    "\n",
    "One notable concern is potential data leakage from the cholesterol check feature. Individuals with a diabetes diagnosis are often encouraged to monitor cholesterol levels more frequently. If cholesterol check frequency is captured post-diagnosis, the model may learn patterns of disease management rather than risk indicators. RBecause the model is intended for pre-diagnosis risk prediction, removing this feature may be necessary to ensure valid learning. The final model will remove the predictors of cholesterol check or high cholesterol, which may reduce F1 but provide a more accurate generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e5fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the model without chol features\n",
    "def run_no_chol(df, run_shap=True):\n",
    "    clf, X, y = lgbm_model_pipeline(df, ignore_chol=True)\n",
    "    # get train test split labels\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    clf = set_best_params(clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_thresh = find_best_threshold(clf, X_val, y_val)\n",
    "    evaluate_model(clf, X_val, y_val, threshold=best_thresh)\n",
    "    if run_shap:\n",
    "        get_shap_explainer(clf, X_train, sample_size=20000)\n",
    "    return clf\n",
    "\n",
    "\n",
    "final_clf = run_no_chol(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e67b18",
   "metadata": {},
   "source": [
    "# Final Evaluation and Future Notes\n",
    "\n",
    "This model is designed to flag likely cases of diabetes, prioritizing high recall to avoid missing true positives. A recall of 0.82 was achieved, with a precision of only around 0.31. While this lowers the F1 score, it aligns with the goal of screening rather than diagnosis. In real-world applications, whether the model aims to detect all at-risk individuals, confirm diagnoses, or support clinical decisions would inform which evaluation metric to prioritize. This model has room for improvement in its detection, especially in precision, as it sets off many false alarms. While it can find the majority of true cases, the presence of false positives lowers trust in the model's predictions. It would provide insight to individuals who may be concerned about their risk level and want to check if they should consider speaking to a doctor about it. \n",
    "\n",
    "The model’s performance is based on this specific dataset, which, while large, may not fully represent all demographic groups. For example, older adults are overrepresented, and the dataset skews toward individuals with higher socioeconomic status. SHAP analysis suggests that lower income is treated by the model as a risk signal. This could reflect confounding factors like nutrition quality or healthcare access, but might also stem from sampling bias or underlying disparities in data collection. More diverse, representative data would improve generalizability across populations.\n",
    "\n",
    "Given the healthcare context and the serious implications of missing true cases, increasing recall at the expense of precision is a justifiable tradeoff. Future improvements may focus on increasing recall further while gradually improving precision through techniques such as more refined feature engineering, additional external data, or advanced ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfd946a",
   "metadata": {},
   "source": [
    "## Saving model\n",
    "The final LightGBM model pipeline, trained without cholesterol features to ensure there is no leakage, is saved using joblib. The file includes the preprocessing pipeline, so it can be used for future prediction without refitting transformers. However, as some feature engineering was done before the pipeline was created, input data would have to undergo those steps as well in order to match the model's input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57d188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(final_clf, 'diabetes_model_pipeline.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
